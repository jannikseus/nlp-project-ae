{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [],
   "source": [
    "# imports\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from numpy.core import overrides\n",
    "from datasets import load_dataset, Dataset\n",
    "from datasets import Features\n",
    "from datasets import Sequence\n",
    "from datasets import ClassLabel\n",
    "from datasets import Value\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, BertConfig, AutoModelForSequenceClassification, \\\n",
    "    TrainingArguments, Trainer, AutoModelForTokenClassification\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:13.008340600Z",
     "start_time": "2023-07-31T10:47:12.996330100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [],
   "source": [
    "RES_PATH = os.path.abspath(\"../resources/data/\") + \"/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:13.034549700Z",
     "start_time": "2023-07-31T10:47:13.000334Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [],
   "source": [
    "def load_dataset_dict(dataset_name, dataset_path, limit=None):\n",
    "    class_label = Sequence(ClassLabel(num_classes=3, names=[\"B\", \"I\", \"O\"]))\n",
    "\n",
    "    with open(dataset_path + dataset_name + \"/train.json\", \"r\", encoding=\"utf-8\") as file_train:\n",
    "        raw_train = pd.read_json(file_train, encoding=\"utf-8\", orient=\"index\").head(limit).fillna(\"\").rename(columns={\"label\": \"labels\"})\n",
    "    with open(dataset_path + dataset_name + \"/test.json\", \"r\", encoding=\"utf-8\") as file_test:\n",
    "        raw_test = pd.read_json(file_test, encoding=\"utf-8\", orient=\"index\").head(limit).fillna(\"\").rename(columns={\"label\": \"labels\"})\n",
    "    with open(dataset_path + dataset_name + \"/dev.json\", \"r\", encoding=\"utf-8\") as file_dev:\n",
    "        raw_dev = pd.read_json(file_dev, encoding=\"utf-8\", orient=\"index\").head(limit).fillna(\"\").rename(columns={\"label\": \"labels\"})\n",
    "\n",
    "    return datasets.DatasetDict({\n",
    "        \"train\": Dataset.from_pandas(raw_train, preserve_index=True).rename_column(\"__index_level_0__\", \"id\").cast_column(\"labels\", class_label),\n",
    "        \"test\": Dataset.from_pandas(raw_test, preserve_index=True).rename_column(\"__index_level_0__\", \"id\").cast_column(\"labels\", class_label),\n",
    "        \"dev\": Dataset.from_pandas(raw_dev, preserve_index=True).rename_column(\"__index_level_0__\", \"id\").cast_column( \"labels\", class_label)\n",
    "    })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:13.034549700Z",
     "start_time": "2023-07-31T10:47:13.016533500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "287ab9b425a0435db94ee91a8738910b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "94d6e15274904d0eb0d1f14ebd276cbf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3168142c40a4f14a8e015ff685f8387"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c63dcf93fcf45079e31ae985c0f9731"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d97bffecddc4259b489563f38db7196"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0a4957807a5452dadee9433bb49e65b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "laptop_dataset_dict = load_dataset_dict(\"laptop\", RES_PATH, 10)\n",
    "rest_dataset_dict = load_dataset_dict(\"rest\", RES_PATH, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:13.144644900Z",
     "start_time": "2023-07-31T10:47:13.032548400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "data": {
      "text/plain": "{'labels': [0, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2],\n 'sentence': ['Keyboard',\n  'is',\n  'great',\n  'but',\n  'primary',\n  'and',\n  'secondary',\n  'control',\n  'buttons',\n  'could',\n  'be',\n  'more',\n  'durable',\n  '.'],\n 'id': 0}"
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_dataset_dict[\"train\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:13.158976200Z",
     "start_time": "2023-07-31T10:47:13.144644900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "outputs": [
    {
     "data": {
      "text/plain": "['B', 'I', 'O']"
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {\n",
    "    \"B\": 0,\n",
    "    \"I\": 1,\n",
    "    \"O\": 2\n",
    "}\n",
    "\n",
    "label_list = rest_dataset_dict[\"train\"].features[\"labels\"].feature.names\n",
    "#label_list = list(map(label2id.get, label_list))\n",
    "label_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:13.205627100Z",
     "start_time": "2023-07-31T10:47:13.159976200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [],
   "source": [
    "bert_auto_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:13.332473500Z",
     "start_time": "2023-07-31T10:47:13.175975300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 2, 2, 0]"
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = rest_dataset_dict[\"train\"][0]\n",
    "tokenized_input = bert_auto_tokenizer(example[\"sentence\"], truncation=True, padding=True, is_split_into_words=True)\n",
    "tokens = bert_auto_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "example[\"labels\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:13.346376500Z",
     "start_time": "2023-07-31T10:47:13.331473300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [],
   "source": [
    "max_length = 100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:13.376971900Z",
     "start_time": "2023-07-31T10:47:13.347377Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(batch_data):\n",
    "    tokenized_inputs = bert_auto_tokenizer(batch_data[\"sentence\"], truncation=True, padding=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(batch_data[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100 -> ignored by PT\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:13.378973300Z",
     "start_time": "2023-07-31T10:47:13.365062400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ec0e66d5a0d431b989b528e2ce309c7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12aea65327c748b19cad13ee1ccdf25d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7aefbb608664e2fbe6f7759a50949c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "492ec502bd614ee3b814494002dcc932"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4539f05d266a4615aad4e84d1e155fd6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/10 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d49ea95ac9e64bc9a4758a2c8b4c9e6c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_rest_dataset_dict = rest_dataset_dict.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_laptop_dataset_dict = laptop_dataset_dict.map(tokenize_and_align_labels, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:13.458044900Z",
     "start_time": "2023-07-31T10:47:13.378973300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=bert_auto_tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:13.476060400Z",
     "start_time": "2023-07-31T10:47:13.459046300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "outputs": [],
   "source": [
    "#clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "clf_metrics = evaluate.load(\"seqeval\")\n",
    "#clf_metrics = evaluate.evaluator(\"text-classification\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:14.152001Z",
     "start_time": "2023-07-31T10:47:13.474058900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    print(labels)\n",
    "    true_predictions = []\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for (p, l) in zip(prediction, label):\n",
    "            if l != -100:\n",
    "                true_predictions.append(label_list[p])\n",
    "\n",
    "    true_labels = []\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for (p, l) in zip(prediction, label):\n",
    "            if l != -100:\n",
    "                true_labels.append(label_list[l])\n",
    "\n",
    "    results = clf_metrics.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:14.166446600Z",
     "start_time": "2023-07-31T10:47:14.151000100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: \"B\",\n",
    "    1: \"I\",\n",
    "    2: \"O\",\n",
    "}\n",
    "label2id = {\n",
    "    \"B\": 0,\n",
    "    \"I\": 1,\n",
    "    \"O\": 2\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:14.184460200Z",
     "start_time": "2023-07-31T10:47:14.166446600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_bert = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3, id2label=id2label, label2id=label2id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:14.610031300Z",
     "start_time": "2023-07-31T10:47:14.182458500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert-base-uncased_auto-seq-model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model_bert,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_laptop_dataset_dict[\"train\"],\n",
    "    eval_dataset=tokenized_laptop_dataset_dict[\"test\"],\n",
    "    tokenizer=bert_auto_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:14.628047500Z",
     "start_time": "2023-07-31T10:47:14.597019100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jannik\\programming_projects\\nlp-project-ae\\venv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/2 : < :, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-100    0    1    2    2    2    2    2    2    2    2    2    2    2\n",
      "     2    2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100    0    1    2    2    2    2    2    2    2    2    2    2    2\n",
      "     2    2    2    2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100    2    2    2    2    2    2    2 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100    0    1    2    2    2 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100    2    2    2    2    2    0    1    2    0 -100    1    2 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100    2    2    2    2    2    2 -100    2    2    2    2    2    2\n",
      "     2    2    2    2    2    2    2    2    2    2    2    2    2    2\n",
      "     2    2    2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100    2    2    2    2    2    2    2    0    1    2    2    2    2\n",
      "     2    2    2    2    2 -100    0    1    2    2    2 -100    2    2\n",
      "     2    2    2    2    2    2    2    2    2    2 -100 -100    2    2\n",
      "     2    2    2    2    2    0    1    2 -100]\n",
      " [-100    2    2    2    2    2 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100    2    0    1    1    1    1    2    2    2 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100]\n",
      " [-100    2    2 -100    2    2    2    2    2    2    2    0    2 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      "  -100 -100 -100 -100 -100 -100 -100 -100 -100]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Got a string but expected a list instead: 'B'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[268], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\programming_projects\\nlp-project-ae\\venv\\lib\\site-packages\\transformers\\trainer.py:1645\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[0;32m   1640\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_wrapped \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\n\u001B[0;32m   1642\u001B[0m inner_training_loop \u001B[38;5;241m=\u001B[39m find_executable_batch_size(\n\u001B[0;32m   1643\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inner_training_loop, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_batch_size, args\u001B[38;5;241m.\u001B[39mauto_find_batch_size\n\u001B[0;32m   1644\u001B[0m )\n\u001B[1;32m-> 1645\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1646\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1647\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1648\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1649\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1650\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\programming_projects\\nlp-project-ae\\venv\\lib\\site-packages\\transformers\\trainer.py:2035\u001B[0m, in \u001B[0;36mTrainer._inner_training_loop\u001B[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2032\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol\u001B[38;5;241m.\u001B[39mshould_training_stop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   2034\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallback_handler\u001B[38;5;241m.\u001B[39mon_epoch_end(args, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcontrol)\n\u001B[1;32m-> 2035\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_log_save_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_loss\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2037\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m DebugOption\u001B[38;5;241m.\u001B[39mTPU_METRICS_DEBUG \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mdebug:\n\u001B[0;32m   2038\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_torch_tpu_available():\n\u001B[0;32m   2039\u001B[0m         \u001B[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001B[39;00m\n",
      "File \u001B[1;32m~\\programming_projects\\nlp-project-ae\\venv\\lib\\site-packages\\transformers\\trainer.py:2321\u001B[0m, in \u001B[0;36mTrainer._maybe_log_save_evaluate\u001B[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001B[0m\n\u001B[0;32m   2319\u001B[0m         metrics\u001B[38;5;241m.\u001B[39mupdate(dataset_metrics)\n\u001B[0;32m   2320\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2321\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2322\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_report_to_hp_search(trial, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mglobal_step, metrics)\n\u001B[0;32m   2324\u001B[0m \u001B[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001B[39;00m\n",
      "File \u001B[1;32m~\\programming_projects\\nlp-project-ae\\venv\\lib\\site-packages\\transformers\\trainer.py:3053\u001B[0m, in \u001B[0;36mTrainer.evaluate\u001B[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[0;32m   3050\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m   3052\u001B[0m eval_loop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprediction_loop \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39muse_legacy_prediction_loop \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluation_loop\n\u001B[1;32m-> 3053\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43meval_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3054\u001B[0m \u001B[43m    \u001B[49m\u001B[43meval_dataloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3055\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdescription\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mEvaluation\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3056\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001B[39;49;00m\n\u001B[0;32m   3057\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# self.args.prediction_loss_only\u001B[39;49;00m\n\u001B[0;32m   3058\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprediction_loss_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   3059\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3060\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_key_prefix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3061\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3063\u001B[0m total_batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39meval_batch_size \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mworld_size\n\u001B[0;32m   3064\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric_key_prefix\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_jit_compilation_time\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m output\u001B[38;5;241m.\u001B[39mmetrics:\n",
      "File \u001B[1;32m~\\programming_projects\\nlp-project-ae\\venv\\lib\\site-packages\\transformers\\trainer.py:3353\u001B[0m, in \u001B[0;36mTrainer.evaluation_loop\u001B[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001B[0m\n\u001B[0;32m   3349\u001B[0m         metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_metrics(\n\u001B[0;32m   3350\u001B[0m             EvalPrediction(predictions\u001B[38;5;241m=\u001B[39mall_preds, label_ids\u001B[38;5;241m=\u001B[39mall_labels, inputs\u001B[38;5;241m=\u001B[39mall_inputs)\n\u001B[0;32m   3351\u001B[0m         )\n\u001B[0;32m   3352\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 3353\u001B[0m         metrics \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mEvalPrediction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_preds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_labels\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3354\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3355\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m {}\n",
      "Cell \u001B[1;32mIn[264], line 18\u001B[0m, in \u001B[0;36mcompute_metrics\u001B[1;34m(eval_pred)\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m l \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m:\n\u001B[0;32m     16\u001B[0m             true_labels\u001B[38;5;241m.\u001B[39mappend(label_list[l])\n\u001B[1;32m---> 18\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mclf_metrics\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredictions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrue_predictions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreferences\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrue_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprecision\u001B[39m\u001B[38;5;124m\"\u001B[39m: results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moverall_precision\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrecall\u001B[39m\u001B[38;5;124m\"\u001B[39m: results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moverall_recall\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m\"\u001B[39m: results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moverall_f1\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m: results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moverall_accuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     24\u001B[0m }\n",
      "File \u001B[1;32m~\\programming_projects\\nlp-project-ae\\venv\\lib\\site-packages\\evaluate\\module.py:432\u001B[0m, in \u001B[0;36mEvaluationModule.compute\u001B[1;34m(self, predictions, references, **kwargs)\u001B[0m\n\u001B[0;32m    429\u001B[0m compute_kwargs \u001B[38;5;241m=\u001B[39m {k: kwargs[k] \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m kwargs \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_feature_names()}\n\u001B[0;32m    431\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(v \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[1;32m--> 432\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd_batch(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs)\n\u001B[0;32m    433\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_finalize()\n\u001B[0;32m    435\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache_file_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\programming_projects\\nlp-project-ae\\venv\\lib\\site-packages\\evaluate\\module.py:485\u001B[0m, in \u001B[0;36mEvaluationModule.add_batch\u001B[1;34m(self, predictions, references, **kwargs)\u001B[0m\n\u001B[0;32m    483\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, column \u001B[38;5;129;01min\u001B[39;00m batch\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    484\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(column) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 485\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_enforce_nested_string_type\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselected_feature_format\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    486\u001B[0m batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mselected_feature_format\u001B[38;5;241m.\u001B[39mencode_batch(batch)\n\u001B[0;32m    487\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwriter\u001B[38;5;241m.\u001B[39mwrite_batch(batch)\n",
      "File \u001B[1;32m~\\programming_projects\\nlp-project-ae\\venv\\lib\\site-packages\\evaluate\\module.py:714\u001B[0m, in \u001B[0;36mEvaluationModule._enforce_nested_string_type\u001B[1;34m(self, schema, obj)\u001B[0m\n\u001B[0;32m    712\u001B[0m \u001B[38;5;66;03m# schema.feature is not a dict\u001B[39;00m\n\u001B[0;32m    713\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(obj, \u001B[38;5;28mstr\u001B[39m):  \u001B[38;5;66;03m# don't interpret a string as a list\u001B[39;00m\n\u001B[1;32m--> 714\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGot a string but expected a list instead: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mobj\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    715\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    716\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: Got a string but expected a list instead: 'B'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T10:47:16.992587Z",
     "start_time": "2023-07-31T10:47:14.628047500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#ps=trainer.predict(laptop_dataset_dict_enc[\"dev\"])\n",
    "#print(ps.predictions.shape, ps.label_ids.shape)\n",
    "bert_auto_tokenizer.convert_tokens_to_ids()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.evaluate(laptop_dataset_dict[\"dev\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model evaluation with metrics precision, recall, accuracy, f1-score and confusion matrix\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
