{
 "cells": [
  {
   "cell_type": "raw",
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "outputs": [],
   "source": [
    "# imports\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "from datasets import Features\n",
    "from datasets import Sequence\n",
    "from datasets import ClassLabel\n",
    "from datasets import Value\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, BertConfig, AutoModelForSequenceClassification, \\\n",
    "    DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:04.693975Z",
     "start_time": "2023-08-02T12:19:04.663666500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "outputs": [],
   "source": [
    "RES_PATH = os.path.abspath(\"../resources/data/\") + \"/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:04.735012200Z",
     "start_time": "2023-08-02T12:19:04.671955900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "outputs": [],
   "source": [
    "# def load_dataset_dict(dataset_name, dataset_path, limit=None):\n",
    "#     class_label = Sequence(ClassLabel(num_classes=3, names=[\"B\", \"I\", \"O\"]))\n",
    "#     id_type = Value(dtype='utf8', id=None)\n",
    "#\n",
    "#     with open(dataset_path + dataset_name + \"/train.json\", \"r\", encoding=\"utf-8\") as file_train:\n",
    "#         raw_train = pd.read_json(file_train, encoding=\"utf-8\", orient=\"index\").head(limit).fillna(\"\").rename(columns={\"label\": \"labels\"})\n",
    "#     with open(dataset_path + dataset_name + \"/test.json\", \"r\", encoding=\"utf-8\") as file_test:\n",
    "#         raw_test = pd.read_json(file_test, encoding=\"utf-8\", orient=\"index\").head(limit).fillna(\"\").rename(columns={\"label\": \"labels\"})\n",
    "#     with open(dataset_path + dataset_name + \"/dev.json\", \"r\", encoding=\"utf-8\") as file_dev:\n",
    "#         raw_dev = pd.read_json(file_dev, encoding=\"utf-8\", orient=\"index\").head(limit).fillna(\"\").rename(columns={\"label\": \"labels\"})\n",
    "#\n",
    "#     return datasets.DatasetDict({\n",
    "#         \"train\": Dataset.from_pandas(raw_train, preserve_index=True).rename_column(\"__index_level_0__\", \"id\").cast_column(\"labels\", class_label).cast_column(\"id\", id_type),\n",
    "#         \"test\": Dataset.from_pandas(raw_test, preserve_index=True).rename_column(\"__index_level_0__\", \"id\").cast_column(\"labels\", class_label).cast_column(\"id\", id_type),\n",
    "#         \"dev\": Dataset.from_pandas(raw_dev, preserve_index=True).rename_column(\"__index_level_0__\", \"id\").cast_column( \"labels\", class_label).cast_column(\"id\", id_type)\n",
    "#     })"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:04.735012200Z",
     "start_time": "2023-08-02T12:19:04.687969600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "outputs": [],
   "source": [
    "def load_dataset_dict(dataset_name, dataset_path, limit=None):\n",
    "    train_file = dataset_path + dataset_name + \"/train.json\"\n",
    "    test_file = dataset_path + dataset_name + \"/test.json\"\n",
    "    dev_file = dataset_path + dataset_name + \"/dev.json\"\n",
    "\n",
    "    return load_dataset(\"json\", data_files={'train':train_file, 'validation':dev_file, 'test':test_file},\n",
    "                        features=Features({\n",
    "                            \"id\": Value(dtype='string', id=None),\n",
    "                            \"label\": Sequence(ClassLabel(num_classes=3, names=[\"B\", \"I\", \"O\"]), length=-1, id=None),\n",
    "                            \"sentence\": Sequence(Value(dtype='string', id=None), length=-1, id=None),\n",
    "                        })).rename_column(\"label\", \"labels\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:04.735012200Z",
     "start_time": "2023-08-02T12:19:04.705985800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/jannik/.cache/huggingface/datasets/json/default-52fdde12eb95d486/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5caf07729074d109a04ff604571d9a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "laptop_dataset_dict = load_dataset_dict(\"test\", RES_PATH)\n",
    "#rest_dataset_dict = load_dataset_dict(\"rest\", RES_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:05.266579600Z",
     "start_time": "2023-08-02T12:19:04.720999600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': '0',\n 'labels': [0, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2],\n 'sentence': ['Keyboard',\n  'is',\n  'great',\n  'but',\n  'primary',\n  'and',\n  'secondary',\n  'control',\n  'buttons',\n  'could',\n  'be',\n  'more',\n  'durable',\n  '.']}"
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop_dataset_dict[\"train\"][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:05.288599600Z",
     "start_time": "2023-08-02T12:19:05.266579600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "outputs": [
    {
     "data": {
      "text/plain": "['B', 'I', 'O']"
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label_list = laptop_dataset_dict[\"train\"].features[\"label\"].feature.names # [\"B\", \"I\", \"O\"]\n",
    "label_list = [\"B\", \"I\", \"O\"]\n",
    "label_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:05.290601500Z",
     "start_time": "2023-08-02T12:19:05.267581Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:05.305614500Z",
     "start_time": "2023-08-02T12:19:05.284596100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "outputs": [],
   "source": [
    "bert_auto_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:05.457497200Z",
     "start_time": "2023-08-02T12:19:05.300610300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "outputs": [
    {
     "data": {
      "text/plain": "['[CLS]',\n 'keyboard',\n 'is',\n 'great',\n 'but',\n 'primary',\n 'and',\n 'secondary',\n 'control',\n 'buttons',\n 'could',\n 'be',\n 'more',\n 'durable',\n '.',\n '[SEP]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]',\n '[PAD]']"
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = laptop_dataset_dict[\"train\"][0]\n",
    "tokenized_input = bert_auto_tokenizer(example[\"sentence\"], is_split_into_words=True,padding='max_length', truncation=True, max_length=87)\n",
    "tokens = bert_auto_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:05.459500900Z",
     "start_time": "2023-08-02T12:19:05.457497200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(batch_data):\n",
    "    tokenized_inputs = bert_auto_tokenizer(batch_data[\"sentence\"], is_split_into_words=True, padding='max_length', truncation=True, max_length=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(batch_data[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100 -> ignored by PT\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:05.488607900Z",
     "start_time": "2023-08-02T12:19:05.458500300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/30 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7b42a39471745f3a0bbaf7012eb3816"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/3 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c65b14d8a4b44b9eab13a17d151a3b68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/8 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "081c4d1bd2cb4a2dae0bc0f60a2aafa4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenized_rest_dataset_dict = rest_dataset_dict.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_laptop_dataset_dict = laptop_dataset_dict.map(tokenize_and_align_labels, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:05.568680800Z",
     "start_time": "2023-08-02T12:19:05.488607900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': Value(dtype='string', id=None),\n 'labels': Sequence(feature=ClassLabel(names=['B', 'I', 'O'], id=None), length=-1, id=None),\n 'sentence': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_laptop_dataset_dict[\"train\"].features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:05.573684500Z",
     "start_time": "2023-08-02T12:19:05.568680800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=bert_auto_tokenizer, padding=True, max_length=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:05.600709100Z",
     "start_time": "2023-08-02T12:19:05.569681600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "outputs": [],
   "source": [
    "#clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "#clf_metrics = evaluate.load(\"seqeval\")\n",
    "#clf_metrics = evaluate.evaluator(\"text-classification\")\n",
    "#ls = [label_list[i] for i in example[\"labels\"]]\n",
    "#clf_metrics.compute(predictions=[ls], references=[ls])\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "f1_metric = evaluate.load(\"f1\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:08.214891400Z",
     "start_time": "2023-08-02T12:19:05.600709100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "outputs": [],
   "source": [
    "labels = [label_list[i] for i in example[\"labels\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:08.220897900Z",
     "start_time": "2023-08-02T12:19:08.200883Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = []\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for (p, l) in zip(prediction, label):\n",
    "            if l != -100:\n",
    "                true_predictions.append(label_list[p])\n",
    "\n",
    "    true_labels = []\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        for (p, l) in zip(prediction, label):\n",
    "            if l != -100:\n",
    "                true_labels.append(label_list[l])\n",
    "\n",
    "    true_labels = [label2id[item] for item in true_labels]\n",
    "    true_predictions = [label2id[item] for item in true_predictions]\n",
    "\n",
    "    results = {}\n",
    "    results.update(accuracy_metric.compute(predictions=true_predictions, references=true_labels))\n",
    "    results.update(precision_metric.compute(predictions=true_predictions, references=true_labels, average='micro'))\n",
    "    results.update(recall_metric.compute(predictions=true_predictions, references=true_labels, average='micro'))\n",
    "    results.update(f1_metric.compute(predictions=true_predictions, references=true_labels, average='micro'))\n",
    "\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:08.246918700Z",
     "start_time": "2023-08-02T12:19:08.219896500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "outputs": [],
   "source": [
    "id2label = {\n",
    "    0: \"B\",\n",
    "    1: \"I\",\n",
    "    2: \"O\",\n",
    "}\n",
    "label2id = {\n",
    "    \"B\": 0,\n",
    "    \"I\": 1,\n",
    "    \"O\": 2\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:08.251923300Z",
     "start_time": "2023-08-02T12:19:08.232921100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_token_classificator = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3, id2label=id2label, label2id=label2id)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:08.675326400Z",
     "start_time": "2023-08-02T12:19:08.247919200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert-base-uncased_auto-seq-model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    #save_steps=100.0,\n",
    "    #save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:08.700348700Z",
     "start_time": "2023-08-02T12:19:08.662204100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=bert_token_classificator,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_laptop_dataset_dict[\"train\"],\n",
    "    eval_dataset=tokenized_laptop_dataset_dict[\"test\"],\n",
    "    tokenizer=bert_auto_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:08.723370400Z",
     "start_time": "2023-08-02T12:19:08.678328900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jannik\\programming_projects\\nlp-project-ae\\venv\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "C:\\Users\\jannik\\programming_projects\\nlp-project-ae\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/2 : < :, Epoch 0.50/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=2, training_loss=1.1292027235031128, metrics={'train_runtime': 2.9992, 'train_samples_per_second': 10.003, 'train_steps_per_second': 0.667, 'total_flos': 258759060300.0, 'train_loss': 1.1292027235031128, 'epoch': 1.0})"
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:12.060454900Z",
     "start_time": "2023-08-02T12:19:08.710358300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "outputs": [],
   "source": [
    "#ps=trainer.predict(laptop_dataset_dict_enc[\"dev\"])\n",
    "#print(ps.predictions.shape, ps.label_ids.shape)\n",
    "#bert_auto_tokenizer.convert_tokens_to_ids(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:12.060454900Z",
     "start_time": "2023-08-02T12:19:12.044440300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "outputs": [],
   "source": [
    "#trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:12.066460700Z",
     "start_time": "2023-08-02T12:19:12.060454900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jannik\\programming_projects\\nlp-project-ae\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2395: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 1.0521329641342163,\n 'eval_accuracy': 0.48507462686567165,\n 'eval_precision': 0.48507462686567165,\n 'eval_recall': 0.48507462686567165,\n 'eval_f1': 0.48507462686567165,\n 'eval_runtime': 0.2582,\n 'eval_samples_per_second': 30.98,\n 'eval_steps_per_second': 3.872,\n 'epoch': 1.0}"
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:12.362729400Z",
     "start_time": "2023-08-02T12:19:12.061456400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "outputs": [],
   "source": [
    "#trainer.evaluate(laptop_dataset_dict[\"dev\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:12.385750600Z",
     "start_time": "2023-08-02T12:19:12.362729400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [
    "# model evaluation with metrics precision, recall, accuracy, f1-score and confusion matrix\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:12.386751100Z",
     "start_time": "2023-08-02T12:19:12.364730800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:12.410773100Z",
     "start_time": "2023-08-02T12:19:12.383748600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:12.416778400Z",
     "start_time": "2023-08-02T12:19:12.410773100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:12.442802400Z",
     "start_time": "2023-08-02T12:19:12.412775200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:12.447806400Z",
     "start_time": "2023-08-02T12:19:12.442802400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:12.474831300Z",
     "start_time": "2023-08-02T12:19:12.443803300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:12.479835700Z",
     "start_time": "2023-08-02T12:19:12.474831300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:12.506390900Z",
     "start_time": "2023-08-02T12:19:12.475832400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:12.511395800Z",
     "start_time": "2023-08-02T12:19:12.506390900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T12:19:12.538395200Z",
     "start_time": "2023-08-02T12:19:12.508393Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
